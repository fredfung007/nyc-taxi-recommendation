Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.3.0
      /_/

Using Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)
Type in expressions to have them evaluated.
Type :help for more information.
Spark context available as sc.
SQL context available as sqlContext.
Loading ./taxi-weather.scala...
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.regression.LinearRegressionModel
import org.apache.spark.mllib.regression.LinearRegressionWithSGD
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.evaluation.RegressionMetrics
import org.apache.spark.mllib.util.MLUtils
import org.apache.spark.mllib.tree.RandomForest
import org.apache.spark.mllib.tree.model.RandomForestModel
import org.apache.spark.mllib.tree.GradientBoostedTrees
import org.apache.spark.mllib.tree.configuration.BoostingStrategy
import org.apache.spark.mllib.tree.model.GradientBoostedTreesModel
import org.apache.spark.SparkContext._
import org.apache.spark.mllib.feature.Normalizer
warning: there were 1 feature warning(s); re-run with -feature for details
bool2int: (b: Boolean)Int
data: org.apache.spark.rdd.RDD[String] = /user/qf264/midtown-2012 MapPartitionsRDD[1] at textFile at <console>:38
parsedData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[2] at map at <console>:40
normalizer: org.apache.spark.mllib.feature.Normalizer = org.apache.spark.mllib.feature.Normalizer@4a9acce1
data_norm: org.apache.spark.rdd.RDD[(Double, org.apache.spark.mllib.linalg.Vector)] = MapPartitionsRDD[3] at map at <console>:44
parsedData_norm: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[4] at map at <console>:46
splits: Array[org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint]] = Array(PartitionwiseSampledRDD[5] at randomSplit at <console>:48, PartitionwiseSampledRDD[6] at randomSplit at <console>:48, PartitionwiseSampledRDD[7] at randomSplit at <console>:48)
trainingData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = PartitionwiseSampledRDD[5] at randomSplit at <console>:48
valData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = PartitionwiseSampledRDD[6] at randomSplit at <console>:48
testData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = PartitionwiseSampledRDD[7] at randomSplit at <console>:48
categoricalFeaturesInfo: scala.collection.immutable.Map[Int,Int] = Map()
numTrees: Int = 22
featureSubsetStrategy: String = all
impurity: String = variance
maxDepth: Int = 20
maxBins: Int = 32
RFmodel: org.apache.spark.mllib.tree.model.RandomForestModel = 
TreeEnsembleModel regressor with 22 trees

trainresult: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[150] at map at <console>:52
metrics: org.apache.spark.mllib.evaluation.RegressionMetrics = org.apache.spark.mllib.evaluation.RegressionMetrics@7107ec35
training R-squared = 0.4474746529184134
valresult: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[152] at map at <console>:54
metrics: org.apache.spark.mllib.evaluation.RegressionMetrics = org.apache.spark.mllib.evaluation.RegressionMetrics@5e0b2ae1
validation R-squared = 0.3885881314988584
testresult: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[154] at map at <console>:54
metrics: org.apache.spark.mllib.evaluation.RegressionMetrics = org.apache.spark.mllib.evaluation.RegressionMetrics@242e5af3
test R-squared = 0.3849484174528446
warning: there were 1 deprecation warning(s); re-run with -deprecation for details
